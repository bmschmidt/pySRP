{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classifier training using Tensorflow Estimators\n",
    "\n",
    "Tensorflow's Estimator class takes a lot of the work out of building transferrable machine learning models; you can, for example, push a model into a javascript version that will live on the web, or swap out models of the very few types for which pre-built estimators exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import SRP\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The goal here is to learn how to classify books by their two-letter library of congress classification. For example:\n",
    "BF is psychology. First we read in a CSV with ids and classifications for about 2,000,000 books.\n",
    "\n",
    "Note that you could replace this csv with any other two-column dataset of htid and categorical labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"/home/bschmidt/Dropbox/hathi_metadata/data_to_classify_on/lc_ic.csv.gz\", names=[\"htid\", \"lc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now I build a list of the possible category values and sort it alphabetically. Note that I've already pruned this down to a manageable number (221) by removing erroneous labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 221 categories\n"
     ]
    }
   ],
   "source": [
    "all_cats = list(set(list(metadata.lc)))\n",
    "all_cats.sort()\n",
    "print(\"There are {} categories\".format(len(all_cats)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A lookup dictionary stores the classification for each individual volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lookup = dict(zip(metadata.htid, metadata.lc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I'm using a single-precision, 1280 dimensional feature set. If you want to use 640 dimensional features, that can be changed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bytes = 2\n",
    "dims = 640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now I need an iterator function to send data to tensorflow. Tensorflow estimators love functions; so this\n",
    "is a function that returns a function. That's a little weird for python, but perfectly normal for R or Javascript or plenty of other languages.\n",
    "\n",
    "Note that you'll need to change the file location in the body of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def base_function(what = 'train', modulo = 10):\n",
    "    def fun():\n",
    "        # Your directory will be different than this.\n",
    "        full_hathi = SRP.Vector_file(\"/home/bschmidt/vector_models/ht-640d-half-precision.bin\".format(what), precision = bytes)\n",
    "        for i, (id, row) in enumerate(full_hathi):\n",
    "            if i % modulo == 0 and what != \"test\":\n",
    "                continue\n",
    "            if i % modulo == 1 and what != \"validate\":\n",
    "                continue\n",
    "            if i % modulo >= 2 and what != \"train\":\n",
    "                continue\n",
    "            if id in lookup:\n",
    "                cat = lookup[id]\n",
    "                # Normalize vectors to unit length.\n",
    "                row = row/np.linalg.norm(row.astype('<f4'))\n",
    "                yield (row, cat)\n",
    "    return fun\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can create train, test, and validate functions. These are functions that return an iterator function that itself returns one entry at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = base_function('train')\n",
    "test = base_function('test')\n",
    "validate = base_function('validate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now onto building a tensorflow estimator. First we need to define a numeric feature column which tells the estimator class about the input data: a 1280 dimnesional numeric vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dtype = tf.float32\n",
    "\n",
    "numeric_feature_column = \\\n",
    "    tf.feature_column.numeric_column(key=\"embedding\",\n",
    "                                     shape = [dims], \n",
    "                                     dtype= dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a DNN classifier. I use 1500 hidden units here, which is a little less than idea.\n",
    "This also takes the category list we trained earlier; and it uses a directory to store information for later training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f19687245f8>, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_evaluation_master': '', '_is_chief': True, '_service': None, '_tf_random_seed': None, '_task_id': 0, '_model_dir': '/tmp/model2', '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_master': '', '_num_ps_replicas': 0, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_global_id_in_cluster': 0, '_session_config': None}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(feature_columns=[numeric_feature_column],\n",
    "                                       hidden_units = [1500],\n",
    "                                        n_classes = len(all_cats),\n",
    "                                        label_vocabulary = all_cats,\n",
    "                                        dropout = 0.5,\n",
    "                                        model_dir = '/tmp/model2'\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We want not one element at a time, but a tensorflow `Dataset` batched into (for example) 250 books at a time.\n",
    "\n",
    "This is the ugliest part of the code. `Dictize` converts from the tuple format our generator returns to a keyed dictionary for the x values. Technical note: the 'yielder' and 'test_yielder' functions are different because the dataset needs to actually be created inside a functional scope that takes no arguments for the purposes of variable scoping in the estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 250\n",
    "\n",
    "def dictize(x, y):\n",
    "    return ({numeric_feature_column: x}, y)\n",
    "\n",
    "def yielder():\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "    train, (dtype, tf.string), \n",
    "                        (tf.TensorShape([dims]), tf.TensorShape([])))\n",
    "\n",
    "    batches = dataset.map(dictize).repeat().batch(BATCH_SIZE)\n",
    "\n",
    "    return batches\n",
    "\n",
    "def test_yielder():\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        test, (dtype, tf.string), \n",
    "             (tf.TensorShape([dims]), tf.TensorShape([])))\n",
    "\n",
    "    batches = dataset.map(dictize).repeat().batch(BATCH_SIZE)\n",
    "\n",
    "    return batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we're ready to train. We train on the training function, and request 2500 steps which is enough to get through the set once or twice.\n",
    "\n",
    "On a normal laptop, this is a long process--I'd think about leaving it running overnight. But if you use tensorboard you can inspect some of the progress by typing `tensorboard --logdir '/tmp/model2'` into the command line and visiting `localhost:6006` in your browser.\n",
    "\n",
    "Ideally we'd be evaluating performance on the validation data here while it runs, but I'm taking it easy.\n",
    "\n",
    "I'll do 10,000 steps: with a batch size of 250 books at a time, that means 2.5 million books. That's about a single pass through the training data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/model2/model.ckpt.\n",
      "INFO:tensorflow:loss = 1350.954, step = 1\n",
      "INFO:tensorflow:global_step/sec: 15.1715\n",
      "INFO:tensorflow:loss = 817.1722, step = 101 (6.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.75\n",
      "INFO:tensorflow:loss = 858.6796, step = 201 (6.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.5541\n",
      "INFO:tensorflow:loss = 524.1978, step = 301 (7.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6822\n",
      "INFO:tensorflow:loss = 880.43884, step = 401 (6.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9495\n",
      "INFO:tensorflow:loss = 644.6073, step = 501 (6.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1539\n",
      "INFO:tensorflow:loss = 517.4074, step = 601 (7.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1359\n",
      "INFO:tensorflow:loss = 457.95477, step = 701 (7.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.971\n",
      "INFO:tensorflow:loss = 572.84015, step = 801 (6.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7205\n",
      "INFO:tensorflow:loss = 453.17322, step = 901 (7.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.949\n",
      "INFO:tensorflow:loss = 342.863, step = 1001 (7.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.215\n",
      "INFO:tensorflow:loss = 604.35754, step = 1101 (7.034 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1223\n",
      "INFO:tensorflow:loss = 506.5045, step = 1201 (7.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0627\n",
      "INFO:tensorflow:loss = 411.86505, step = 1301 (7.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0983\n",
      "INFO:tensorflow:loss = 530.52374, step = 1401 (7.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7036\n",
      "INFO:tensorflow:loss = 695.3821, step = 1501 (6.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0564\n",
      "INFO:tensorflow:loss = 809.17755, step = 1601 (7.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9708\n",
      "INFO:tensorflow:loss = 459.81866, step = 1701 (7.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9788\n",
      "INFO:tensorflow:loss = 564.40594, step = 1801 (6.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4435\n",
      "INFO:tensorflow:loss = 604.81226, step = 1901 (6.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.3657\n",
      "INFO:tensorflow:loss = 611.63446, step = 2001 (7.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2634\n",
      "INFO:tensorflow:loss = 547.4445, step = 2101 (6.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3189\n",
      "INFO:tensorflow:loss = 633.56476, step = 2201 (6.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7736\n",
      "INFO:tensorflow:loss = 452.58167, step = 2301 (7.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2531\n",
      "INFO:tensorflow:loss = 609.4887, step = 2401 (7.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1869\n",
      "INFO:tensorflow:loss = 506.16394, step = 2501 (6.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9536\n",
      "INFO:tensorflow:loss = 533.0686, step = 2601 (7.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6805\n",
      "INFO:tensorflow:loss = 351.71048, step = 2701 (7.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7751\n",
      "INFO:tensorflow:loss = 525.6358, step = 2801 (6.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6496\n",
      "INFO:tensorflow:loss = 458.30002, step = 2901 (6.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9553\n",
      "INFO:tensorflow:loss = 497.68106, step = 3001 (7.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3124\n",
      "INFO:tensorflow:loss = 333.52762, step = 3101 (6.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.097\n",
      "INFO:tensorflow:loss = 532.4596, step = 3201 (6.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9547\n",
      "INFO:tensorflow:loss = 574.93256, step = 3301 (7.719 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8965\n",
      "INFO:tensorflow:loss = 498.3466, step = 3401 (7.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0344\n",
      "INFO:tensorflow:loss = 571.7913, step = 3501 (6.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8494\n",
      "INFO:tensorflow:loss = 526.9555, step = 3601 (6.734 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.8138\n",
      "INFO:tensorflow:loss = 549.09766, step = 3701 (7.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9991\n",
      "INFO:tensorflow:loss = 689.4115, step = 3801 (6.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9201\n",
      "INFO:tensorflow:loss = 389.5447, step = 3901 (6.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0281\n",
      "INFO:tensorflow:loss = 485.88654, step = 4001 (7.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.657\n",
      "INFO:tensorflow:loss = 217.64255, step = 4101 (6.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5606\n",
      "INFO:tensorflow:loss = 544.39325, step = 4201 (6.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6206\n",
      "INFO:tensorflow:loss = 470.13605, step = 4301 (6.840 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3451\n",
      "INFO:tensorflow:loss = 411.63385, step = 4401 (6.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.79\n",
      "INFO:tensorflow:loss = 474.31177, step = 4501 (6.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9183\n",
      "INFO:tensorflow:loss = 413.60974, step = 4601 (7.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9137\n",
      "INFO:tensorflow:loss = 444.24258, step = 4701 (6.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5054\n",
      "INFO:tensorflow:loss = 414.86804, step = 4801 (6.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4653\n",
      "INFO:tensorflow:loss = 451.69962, step = 4901 (6.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1844\n",
      "INFO:tensorflow:loss = 447.11688, step = 5001 (6.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1266\n",
      "INFO:tensorflow:loss = 475.72626, step = 5101 (6.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.463\n",
      "INFO:tensorflow:loss = 447.83978, step = 5201 (6.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4672\n",
      "INFO:tensorflow:loss = 492.05273, step = 5301 (6.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.045\n",
      "INFO:tensorflow:loss = 440.04358, step = 5401 (6.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4434\n",
      "INFO:tensorflow:loss = 526.6179, step = 5501 (6.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7776\n",
      "INFO:tensorflow:loss = 424.3891, step = 5601 (6.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4351\n",
      "INFO:tensorflow:loss = 610.66766, step = 5701 (6.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.7057\n",
      "INFO:tensorflow:loss = 508.62125, step = 5801 (6.800 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8683\n",
      "INFO:tensorflow:loss = 602.8631, step = 5901 (7.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6665\n",
      "INFO:tensorflow:loss = 457.2767, step = 6001 (7.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6325\n",
      "INFO:tensorflow:loss = 507.33286, step = 6101 (6.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4518\n",
      "INFO:tensorflow:loss = 497.25348, step = 6201 (6.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.9159\n",
      "INFO:tensorflow:loss = 376.90765, step = 6301 (7.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6395\n",
      "INFO:tensorflow:loss = 357.36993, step = 6401 (7.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.726\n",
      "INFO:tensorflow:loss = 548.5192, step = 6501 (7.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1304\n",
      "INFO:tensorflow:loss = 291.7473, step = 6601 (7.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9968\n",
      "INFO:tensorflow:loss = 457.5477, step = 6701 (7.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.2364\n",
      "INFO:tensorflow:loss = 486.73502, step = 6801 (7.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.332\n",
      "INFO:tensorflow:loss = 423.7219, step = 6901 (6.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.1255\n",
      "INFO:tensorflow:loss = 516.6612, step = 7001 (7.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.0511\n",
      "INFO:tensorflow:loss = 424.11334, step = 7101 (7.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0004\n",
      "INFO:tensorflow:loss = 422.0582, step = 7201 (7.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.6329\n",
      "INFO:tensorflow:loss = 256.40256, step = 7301 (7.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.9707\n",
      "INFO:tensorflow:loss = 363.19058, step = 7401 (7.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.8234\n",
      "INFO:tensorflow:loss = 412.27945, step = 7501 (7.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0889\n",
      "INFO:tensorflow:loss = 474.497, step = 7601 (6.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0845\n",
      "INFO:tensorflow:loss = 477.4922, step = 7701 (6.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.4551\n",
      "INFO:tensorflow:loss = 479.04886, step = 7801 (6.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8013\n",
      "INFO:tensorflow:loss = 571.80316, step = 7901 (6.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.1741\n",
      "INFO:tensorflow:loss = 494.90073, step = 8001 (6.590 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.1238\n",
      "INFO:tensorflow:loss = 610.4834, step = 8101 (7.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7636\n",
      "INFO:tensorflow:loss = 474.1873, step = 8201 (7.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2927\n",
      "INFO:tensorflow:loss = 489.36032, step = 8301 (6.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9084\n",
      "INFO:tensorflow:loss = 499.76862, step = 8401 (6.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.3719\n",
      "INFO:tensorflow:loss = 503.863, step = 8501 (6.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8148\n",
      "INFO:tensorflow:loss = 385.4067, step = 8601 (6.323 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8609 into /tmp/model2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 14.6939\n",
      "INFO:tensorflow:loss = 425.8155, step = 8701 (6.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8584\n",
      "INFO:tensorflow:loss = 484.06992, step = 8801 (6.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.076\n",
      "INFO:tensorflow:loss = 538.4522, step = 8901 (6.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8227\n",
      "INFO:tensorflow:loss = 310.6877, step = 9001 (6.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1481\n",
      "INFO:tensorflow:loss = 513.8233, step = 9101 (6.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0606\n",
      "INFO:tensorflow:loss = 369.9548, step = 9201 (6.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0826\n",
      "INFO:tensorflow:loss = 416.74197, step = 9301 (6.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0626\n",
      "INFO:tensorflow:loss = 400.1271, step = 9401 (7.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2472\n",
      "INFO:tensorflow:loss = 505.83978, step = 9501 (6.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9409\n",
      "INFO:tensorflow:loss = 390.69742, step = 9601 (6.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 12.1919\n",
      "INFO:tensorflow:loss = 374.99982, step = 9701 (8.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.0609\n",
      "INFO:tensorflow:loss = 520.3057, step = 9801 (7.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.4091\n",
      "INFO:tensorflow:loss = 378.43762, step = 9901 (7.458 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/model2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 463.49017.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f19686c0390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn = yielder, steps = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluate the classifier performance on the test data.\n",
    "\n",
    "In the paper, I got about 68% accuracy at this task. Here it's a little lower (62%) for a few reasons:\n",
    "\n",
    "1. The dimensionality is half as big, and I'm only using 1500 neurons in the hidden layer.\n",
    "2. The precision is only 2-bytes per integer, not 4. I don't think this makes much of a difference; but it might make some.\n",
    "3. The initializations aren't quite as well thought out--in particular, I haven't taken any steps here to avoid 'dead' neurons in the network by initializing to positive values, etc. \n",
    "4. We're not choosing a stopping point based on the validation set. Based on my previous experience, I think a single pass is probably a little smaller than ideal: we might get better results with 20,000 or 30,000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-05-15:22:12\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model2/model.ckpt-11150\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-05-15:22:18\n",
      "INFO:tensorflow:Saving dict for global step 11150: accuracy = 0.627, average_loss = 1.4050226, global_step = 11150, loss = 351.25568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.627,\n",
       " 'average_loss': 1.4050226,\n",
       " 'global_step': 11150,\n",
       " 'loss': 351.25568}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(test_yielder, steps = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate impressionistically on truly out-of-domain data.\n",
    "\n",
    "Now that we have a model, we'll throw it against some demonstration texts. Here's a function to pull any article from wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Elephants are large mammals of the family Elephantidae and the order Proboscidea. Three species are currently recognised: the African bush elephant (Loxodonta africana), the African forest elephant (L. cyclotis), and the Asian elephant (Elephas maximus). Elephants are scattered throughout sub-Sa...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "def get_wikitext(article_title, language=\"en\"):\n",
    "    response = requests.get(\n",
    "        'https://{}.wikipedia.org/w/api.php'.format(language),\n",
    "        params={\n",
    "            'action': 'parse',\n",
    "            'page': article_title,\n",
    "            'format': 'json',\n",
    "        }\n",
    "    ).json()\n",
    "    raw_html = response['parse']['text']['*']\n",
    "    document = html.document_fromstring(raw_html)\n",
    "    first_p = document.xpath('//p')[0]\n",
    "    body = \"\\n\".join([p.text_content() for p in document.xpath('//p')])\n",
    "    return (body)\n",
    "\n",
    "print(get_wikitext(\"Elephant\")[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, I wrap some prediction code into a function to explore any wikipedia article. You can pull this apart to build a more complicated classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import SRP\n",
    "\n",
    "def predict(article, language='en'):\n",
    "    text = get_wikitext(article, language=language)\n",
    "    print(text[:300].strip() + \"...\")\n",
    "    representation = SRP.SRP(640).stable_transform(text)\n",
    "    representation = representation/np.linalg.norm(representation)\n",
    "\n",
    "    predict_input_fn = tf.estimator.inputs.numpy_input_fn({numeric_feature_column: np.array([representation])},\n",
    "                                                  y=None,\n",
    "                                                  batch_size=1,\n",
    "                                                  num_epochs=1,\n",
    "                                                  shuffle=False)    \n",
    "\n",
    "\n",
    "    p = classifier.predict(predict_input_fn)\n",
    "    predictions = p.__next__()\n",
    "    preds = list(zip(predictions['probabilities'], all_cats))\n",
    "    preds.sort()\n",
    "    preds.reverse()\n",
    "\n",
    "    for i in range(10):\n",
    "        print(\" {:.02%} {}\".format(*preds[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elephant is correctly classed as QL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elephants are large mammals of the family Elephantidae and the order Proboscidea. Three species are currently recognised: the African bush elephant (Loxodonta africana), the African forest elephant (L. cyclotis), and the Asian elephant (Elephas maximus). Elephants are scattered throughout sub-Sa...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model2/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      " 84.42% QL\n",
      " 5.44% GN\n",
      " 3.19% QH\n",
      " 1.36% SF\n",
      " 0.83% G\n",
      " 0.83% GR\n",
      " 0.40% RC\n",
      " 0.36% Q\n",
      " 0.25% GV\n",
      " 0.24% BL\n"
     ]
    }
   ],
   "source": [
    "predict(\"elephant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So is 'rhinoceros': but there's a little more uncertainty here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ceratotherium\n",
      "Dicerorhinus\n",
      "Diceros\n",
      "Rhinoceros\n",
      "Extinct genera, see text\n",
      "\n",
      "A rhinoceros (/raɪˈnɒsərəs/, from Greek  rhinokeros, meaning 'nose-horned', from  rhinos, meaning 'nose', and  kerato/keras, meaning 'horn'), commonly abbreviated to 'rhino', is one of any five extant species of odd-toed ungu...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model2/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      " 35.55% QL\n",
      " 14.03% RC\n",
      " 12.11% QH\n",
      " 6.48% SF\n",
      " 4.56% RA\n",
      " 2.67% TX\n",
      " 2.62% QP\n",
      " 2.16% RM\n",
      " 1.77% Q\n",
      " 1.24% SB\n"
     ]
    }
   ],
   "source": [
    "predict(\"rhinoceros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The German-language article on Immanuel Kant is reasonably classed as 'B' (General Philosophy) rather than PT (German literature),\n",
    "showing that we've learned German-specific rules as well as English ones. It's possible that BD or BH would be more correct, though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immanuel Kant (* 22. April 1724 in Königsberg, Preußen; † 12. Februar 1804 ebenda) war ein deutscher Philosoph der Aufklärung. Kant zählt zu den bedeutendsten Vertretern der abendländischen Philosophie. Sein Werk Kritik der reinen Vernunft kennzeichnet einen Wendepunkt in der Philosophiegeschichte u...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model2/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      " 69.11% B\n",
      " 5.59% BD\n",
      " 3.21% BH\n",
      " 2.45% PT\n",
      " 1.45% BF\n",
      " 1.29% BL\n",
      " 1.21% HM\n",
      " 1.13% LB\n",
      " 0.94% Q\n",
      " 0.91% N\n"
     ]
    }
   ],
   "source": [
    "predict(\"Immanuel Kant\", language='de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "French gets Kant right too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modifier - modifier le code - modifier Wikidata\n",
      "Emmanuel Kant (Immanuel en allemand, prononcé dans cette langue [ɪˈmaːnu̯eːl kant]), né le 22 avril 1724 à Königsberg, capitale de la Prusse-Orientale, et mort dans cette même ville le 12 février 1804, est un philosophe allemand, fondateur du criticism...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model2/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      " 35.84% B\n",
      " 9.62% PN\n",
      " 4.88% BJ\n",
      " 4.74% Z\n",
      " 3.59% N\n",
      " 3.55% BD\n",
      " 2.32% CB\n",
      " 1.99% PQ\n",
      " 1.70% AC\n",
      " 1.69% LA\n"
     ]
    }
   ],
   "source": [
    "predict(\"Emmanuel Kant\", language='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But William James, who is correct in English and French, gets dumped into German history as the model's priors about German-language text overwhelm any psychology or philosophy-specific content here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "William James (* 11. Januar 1842 in New York; † 26. August 1910 in Chocorua, New Hampshire) war ein US-amerikanischer Psychologe und Philosoph. Von 1876 bis 1907 war er Professor für Psychologie und Philosophie an der Harvard University. James gilt sowohl als Begründer der Psychologie in den USA[1]...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model2/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      " 13.55% DD\n",
      " 10.68% B\n",
      " 10.58% PT\n",
      " 6.69% Z\n",
      " 6.40% PN\n",
      " 2.78% PG\n",
      " 2.70% CT\n",
      " 2.40% HX\n",
      " 1.86% D\n",
      " 1.83% BP\n"
     ]
    }
   ],
   "source": [
    "predict(\"William James\", language='de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, the model is *extremely* confident: 98% certainty that Johannes Brahms is an article about music.\n",
    "\n",
    "I've found, experimentally, that these probabilities tend to be useful; but also to overstate the actual accuracy. Probably it should say something more like 93%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johannes Brahms (German: [joˈhanəs ˈbʁaːms]; 7 May 1833 – 3 April 1897) was a German composer and pianist of the Romantic period. Born in Hamburg into a Lutheran family, Brahms spent much of his professional life in Vienna, Austria. His reputation and status as a composer are such that he is some...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model2/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      " 98.00% ML\n",
      " 1.90% MT\n",
      " 0.03% PN\n",
      " 0.01% PR\n",
      " 0.01% GV\n",
      " 0.01% PT\n",
      " 0.01% ND\n",
      " 0.01% M\n",
      " 0.00% CT\n",
      " 0.00% NC\n"
     ]
    }
   ],
   "source": [
    "predict(\"Johannes Brahms\", language='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Intersectionality\" is not philosophy, but Subclass HQ. The family. Marriage. Women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersectionality is an analytic framework that attempts to identify how interlocking systems of power impact those who are most marginalized in society.[1] Intersectionality considers that various forms of social stratification, such as class, race, sexual orientation, age, disability and gender,...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model2/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      " 29.35% HQ\n",
      " 18.72% HV\n",
      " 9.86% HD\n",
      " 9.16% KF\n",
      " 6.72% HM\n",
      " 4.47% K\n",
      " 2.12% JC\n",
      " 1.99% HN\n",
      " 1.77% RA\n",
      " 1.15% HF\n"
     ]
    }
   ],
   "source": [
    "predict(\"Intersectionality\", language=\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boston Red Sox are sports and leisure. Gee, I'm having trouble finding an example that doesn't work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Boston Red Sox are an American professional baseball team based in Boston, Massachusetts. The Red Sox compete in Major League Baseball (MLB) as a member club of the American League (AL) East division. The Red Sox have won eight World Series championships and have played in twelve. In addit...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model2/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      " 84.34% GV\n",
      " 10.00% PN\n",
      " 1.43% F\n",
      " 1.30% E\n",
      " 0.44% PE\n",
      " 0.43% SF\n",
      " 0.26% CT\n",
      " 0.18% QC\n",
      " 0.13% TL\n",
      " 0.11% CS\n"
     ]
    }
   ],
   "source": [
    "predict(\"Boston Red Sox\", language=\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go. A lot of wikipedia is famously Pokémon, but that's not something you can find a lot of in libraries. So it punts--maybe it's 'general literature', maybe it's bibliography (Z--a common catchall category). GV would probably be the best bet, but only shows up in third place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pokémon (Japanese: ポケモン, Hepburn: Pokemon, Japanese: [pokemoɴ]; English: /ˈpoʊkɪˌmɒn, -ki-, -keɪ-/),[1][2][3] also known as Pocket Monsters (ポケットモンスター) in Japan, is a Japanese media franchise managed by The Pokémon Company, a Japanese consortium between Nintendo, Game Freak, and Creatures.[4] The...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model2/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      " 26.16% PN\n",
      " 20.31% Z\n",
      " 10.83% GV\n",
      " 8.43% NC\n",
      " 7.01% TR\n",
      " 2.74% BF\n",
      " 2.31% QL\n",
      " 2.23% N\n",
      " 1.95% Q\n",
      " 1.69% DS\n"
     ]
    }
   ],
   "source": [
    "predict(\"Pokémon\", language=\"en\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
