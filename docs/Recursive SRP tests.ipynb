{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It is possible that a later version of SRP will, instead of hashing each word to a simple binary projection,\n",
    "instead hash it on the basis of all its substrings so that orthographically similar words have similar projections. That requires some additional tricks and more efficient hashing, which are being tested here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from SRP import Vector_file\n",
    "from SRP import SRP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fah = SRP(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "words = [l.rstrip(\"\\n\").decode(\"utf-8\") for l in open(\"/Users/bschmidt/vector_models/words.txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hasher = SRP(320)\n",
    "hasher.dtype = np.int8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6, -2, -2, -2,  4, -6,  2,  0,  4,  0, -4, -8,  0, -2,  4,  0,  0,\n",
       "       -6,  0, -4,  6,  0,  2,  2, -4, -2,  4,  2,  0,  4,  2,  0], dtype=int8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fah.hash_all_substrings(\"foob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "limit = 10000\n",
    "dicto = np.zeros((limit,320))\n",
    "for i in range(limit):\n",
    "    dicto[i] = hasher.hash_all_substrings(words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62776\n",
      "62776\n"
     ]
    }
   ],
   "source": [
    "print len(hasher.known_hashes)\n",
    "print len(hasher.recurse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'principle'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasher.known_hashes[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.,  -1.,   7.,  15.,   1.,   1.,   9.,  -1.,   3.,  -5.,  -7.,\n",
       "        -7.,   1.,  -5.,  -1.,  -7.,  -1.,  -3.,   5.,   9.,   1.,  -3.,\n",
       "         3.,   9.,  -9., -15.,   7.,   3.,  -5.,  -3.,   5.,  11.,  11.,\n",
       "        -5.,  -7.,  -3.,   5.,  -3.,  -9.,   1.,   7.,   3.,  -5.,   5.,\n",
       "         5.,   1.,  -7.,  -3.,   1.,  11.,  -3.,  -1.,   5.,  -3., -11.,\n",
       "        -1.,  -1.,   7.,   3.,  -1.,   9.,   3.,   7.,  -1.,  -5.,  -7.,\n",
       "        13.,  -1.,  -1.,   3.,   3.,  -3.,  11.,  -7.,  13.,  11.,   7.,\n",
       "         9.,  -3.,   5.,  -3., -11.,  -3.,   1.,  -3.,   1.,   1.,  -7.,\n",
       "        11.,   7., -11.,   5.,   7.,  -5.,  -3.,  -3.,  -3.,  -9.,  -9.,\n",
       "         1.,  -7.,  -5.,   1.,  15.,  -1.,  -5.,   5.,   3.,  -3.,  -5.,\n",
       "         9.,  -9.,   1.,  -3.,  11.,  11., -13.,  -3.,  -9.,   3.,   5.,\n",
       "         1.,  -3.,  -1.,   7.,  -1.,   1.,  -3.,   7.,   1.,   5., -13.,\n",
       "        11.,  -1.,  -7.,  13.,   3.,  -3.,  11.,  11.,   5.,  -3.,  -1.,\n",
       "        -1.,  -3.,  -7.,  -1.,  -7.,  -1.,   1.,   1.,  -9.,  13.,   7.,\n",
       "        -7.,   1.,   5.,   9.,  11.,   3.,   1.,   1.,  -9.,  -3.,  -9.,\n",
       "        -3.,  -3.,   1.,  13.,   7.,  -5.,  -1.,   3.,   5.,  -3.,   5.,\n",
       "        -5.,  -3.,  -3.,  -9.,   3.,  -5.,   5.,  -1.,   5.,  -1.,  -3.,\n",
       "         7.,   1.,  -9.,   1.,  -1.,   7.,  -7.,  -9.,  -5.,   1.,   5.,\n",
       "        13.,   5.,  -5., -13.,  -5., -11.,  13.,   7.,   3., -13.,   3.,\n",
       "        -3.,  -3.,   5.,   1.,  -5.,  -3.,  11.,   1.,   5.,  11.,   9.,\n",
       "        13.,  11.,   3., -13., -15.,  -9.,  -5.,  -3.,  -5.,   3.,   1.,\n",
       "        -1.,  -1.,   5., -11.,  -3.,  -5.,  -3.,   5., -11.,   1.,   3.,\n",
       "        -3., -13.,  -7.,  -3.,   1.,   9.,   1.,   3.,   7.,   7.,  -1.,\n",
       "        -3.,  -7.,   3.,   3.,  -5.,   3.,   1.,  -1.,  13.,   1.,   1.,\n",
       "        -1.,  11.,   7.,  -5.,   1., -13.,  -1.,  13.,   7.,  -1.,   3.,\n",
       "         7.,  -3.,  -7.,   5.,   1.,  -3.,  -3.,   3.,  -1.,  -5.,   1.,\n",
       "         7.,  -3.,  -1.,  11.,  -5.,  -3.,   5., -13.,  -1.,  15.,  -3.,\n",
       "        -3.,  -3.,  -1.,   1.,   3.,   5.,   1.,   3.,  -3.,   1.,   7.,\n",
       "        -1.,  -9.,  11.,   3.,   7.,  -1.,  -1.,  -1.,   1.,  -1.,   1.,\n",
       "         5.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicto[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics.pairwise\n",
    "def closest_to(ix,n = 10):\n",
    "    ds = sklearn.metrics.pairwise.cosine_similarity(dicto[ix].reshape(1,-1),dicto)[0]\n",
    "    top = np.argpartition(-ds,n)[:n]\n",
    "    print\n",
    "    returnt = []\n",
    "    for t in top:\n",
    "        returnt.append((ds[t],words[t]))\n",
    "    returnt.sort(reverse = True)\n",
    "    for a,b in returnt:\n",
    "        print \"{:>8.03} {}\".format(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     1.0 the\n",
      "   0.811 them\n",
      "   0.804 they\n",
      "   0.771 thee\n",
      "   0.743 then\n",
      "   0.724 these\n",
      "   0.714 theme\n",
      "   0.713 there\n",
      "   0.692 their\n",
      "   0.686 Other\n",
      "\n",
      "     1.0 of\n",
      "   0.607 o\n",
      "   0.546 off\n",
      "   0.529 f\n",
      "   0.493 fro\n",
      "   0.437 for\n",
      "   0.423 do\n",
      "   0.418 good\n",
      "   0.399 No\n",
      "   0.394 from\n",
      "\n",
      "     1.0 upon\n",
      "   0.436 Upon\n",
      "   0.426 pond\n",
      "   0.365 non\n",
      "   0.355 weapon\n",
      "   0.327 on\n",
      "   0.295 weapons\n",
      "   0.289 con\n",
      "   0.289 won\n",
      "   0.285 respond\n",
      "\n",
      "     1.0 principle\n",
      "   0.871 principles\n",
      "   0.636 principal\n",
      "   0.622 Principles\n",
      "   0.574 principally\n",
      "   0.529 prince\n",
      "   0.442 princes\n",
      "   0.407 princess\n",
      "   0.397 print\n",
      "   0.382 Prince\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10000 is out of bounds for axis 0 with size 10000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b3f126d7b190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclosest_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mclosest_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-abd112987415>\u001b[0m in \u001b[0;36mclosest_to\u001b[0;34m(ix, n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclosest_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdicto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10000 is out of bounds for axis 0 with size 10000"
     ]
    }
   ],
   "source": [
    "closest_to(0)\n",
    "\n",
    "closest_to(1)\n",
    "\n",
    "closest_to(100)\n",
    "\n",
    "closest_to(1000)\n",
    "\n",
    "closest_to(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ix = 1000\n",
    "ds = sklearn.metrics.pairwise.cosine_similarity(dicto[ix].reshape(1,-1),dicto)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 256, 3993, 4908,  803,   31,    3,    3,    1,    1,    1]),\n",
       " array([-0.22981407, -0.10683266,  0.01614875,  0.13913015,  0.26211156,\n",
       "         0.38509297,  0.50807437,  0.63105578,  0.75403719,  0.87701859,  1.        ]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'amazing', u'Amazing']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in words if word==\"amazing\" or word==\"Amazing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62776"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hasher.recurse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out = Vector_file(\"out.bin\",dims=320,mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7ddc37327e9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdicto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<f4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "for id,row in zip(words,dicto):\n",
    "    out.add_row(id.encode(\"utf-8\"),row.astype(\"<f4\"))\n",
    "    \n",
    "out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
